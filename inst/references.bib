@article{blake2012applied,
  title={Applied Bayesian econometrics for central bankers},
  author={Blake, Andrew P and Mumtaz, Haroon and others},
  journal={Technical Books},
  year={2012},
  publisher={Centre for Central Banking Studies, Bank of England}
}

@article{DK2002,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/4140605},
 abstract = {A simulation smoother in state space time series analysis is a procedure for drawing samples from the conditional distribution of state or disturbance vectors given the observations. We present a new technique for this which is both simple and computationally efficient. The treatment includes models with diffuse initial conditions and regression effects. Computational comparisons are made with the previous standard method. Two applications are provided to illustrate the use of the simulation smoother for Gibbs sampling for Bayesian inference and importance sampling for classical inference.},
 author = {J. Durbin and S. J. Koopman},
 journal = {Biometrika},
 number = {3},
 pages = {603-615},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {A Simple and Efficient Simulation Smoother for State Space Time Series Analysis},
 volume = {89},
 year = {2002}
}

@article{CC1994,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/2337125},
 abstract = {We show how to use the Gibbs sampler to carry out Bayesian inference on a linear state space model with errors that are a mixture of normals and coefficients that can switch over time. Our approach simultaneously generates the whole of the state vector given the mixture and coefficient indicator variables and simultaneously generates all the indicator variables conditional on the state vectors. The states are generated efficiently using the Kalman filter. We illustrate our approach by several examples and empirically compare its performance to another Gibbs sampler where the states are generated one at a time. The empirical results suggest that our approach is both practical to implement and dominates the Gibbs sampler that generates the states one at a time.},
 author = {C. K. Carter and R. Kohn},
 journal = {Biometrika},
 number = {3},
 pages = {541-553},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {On Gibbs Sampling for State Space Models},
 volume = {81},
 year = {1994}
}

@article{KoopKorobilis2010,
url = {http://dx.doi.org/10.1561/0800000013},
year = {2010},
volume = {3},
journal = {Foundations and Trends® in Econometrics},
title = {Bayesian Multivariate Time Series Methods for Empirical Macroeconomics},
doi = {10.1561/0800000013},
issn = {1551-3076},
number = {4},
pages = {267-358},
author = {Gary Koop and Dimitris Korobilis}
}

@article{Robertson2005,
 ISSN = {00222879, 15384616},
 URL = {http://www.jstor.org/stable/3839160},
 abstract = {The paper describes a relative entropy procedure for imposing restrictions on simulated forecast distributions from a variety of models. Starting from an empirical forecast distribution for some variables of interest, the technique generates a new empirical distribution that satisfies a set of moment restrictions not used in the construction of the original. The new distribution is informationally as close as possible to the original in the sense of minimizing the Kullback-Leibler Information Criterion, or relative entropy. We illustrate the technique with an example related to monetary policy that shows how to introduce restrictions from economic theory into a model's forecasts.},
 author = {John C. Robertson and Ellis W. Tallman and Charles H. Whiteman},
 journal = {Journal of Money, Credit and Banking},
 number = {3},
 pages = {383-401},
 publisher = {[Wiley, Ohio State University Press]},
 title = {Forecasting Using Relative Entropy},
 volume = {37},
 year = {2005}
}

@article{CogleySargent2005,
  title = "Drifts and volatilities: monetary policies and outcomes in the post \{WWII\} \{US\} ",
  journal = "Review of Economic Dynamics ",
  volume = "8",
  number = "2",
  pages = "262 - 302",
  year = "2005",
  note = "Monetary Policy and Learning ",
  issn = "1094-2025",
  doi = "http://dx.doi.org/10.1016/j.red.2004.10.009",
  url = "http://www.sciencedirect.com/science/article/pii/S1094202505000049",
  author = "Timothy Cogley and Thomas J. Sargent",
  abstract = "For a \{VAR\} with drifting coefficients and stochastic volatilities, we present posterior densities for several objects that are pertinent for designing and evaluating monetary policy. These include measures of inflation persistence, the natural rate of unemployment, a core rate of inflation, and ‘activism coefficients’ for monetary policy rules. Our posteriors imply substantial variation of all of these objects for post \{WWII\} \{US\} data. After adjusting for changes in volatility, persistence of inflation increases during the 1970s, then falls in the 1980s and 1990s. Innovation variances change systematically, being substantially larger in the late 1970s than during other times. Measures of uncertainty about core inflation and the degree of persistence covary positively. We use our posterior distributions to evaluate the power of several tests that have been used to test the null hypothesis of time-invariance of autoregressive coefficients of \{VARs\} against the alternative of time-varying coefficients. Except for one, we find that those tests have low power against the form of time variation captured by our model. "
}


